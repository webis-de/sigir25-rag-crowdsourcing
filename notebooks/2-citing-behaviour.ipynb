{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "def jaccard(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "(\n",
    "    pd.read_json(\"../data/artifacts/responses.jsonl.gz\", lines=True)\n",
    "    .loc[:, [\"response\", \"style\", \"kind\", \"topic\", \"statements\"]]\n",
    "     .merge(\n",
    "        (\n",
    "            pd.read_json(\"../data/raw/study1_retrieval.jsonl.gz\", lines=True)\n",
    "            .loc[:, [\"topic\", \"references_ids\"]]\n",
    "            .rename(columns={\"references_ids\": \"retrieved_ids\"})\n",
    "        ),\n",
    "        on=\"topic\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .assign(cited_ids=lambda df: df[\"statements\"].apply(lambda cell: list(dict.fromkeys([y for x in cell for y in x[\"citations\"]]).keys())))\n",
    "    .loc[:, [\"topic\", \"style\", \"kind\", \"retrieved_ids\", \"cited_ids\"]]\n",
    "    .groupby([\"topic\", \"style\"])\n",
    "    .apply(lambda group: pd.Series({\n",
    "        \"retrieved_ids\": group[\"retrieved_ids\"].values[0],\n",
    "        \"cited_ids_human\": group.loc[group[\"kind\"] == \"human\", \"cited_ids\"].values[0],\n",
    "        \"cited_ids_llm\": group.loc[group[\"kind\"] == \"llm\", \"cited_ids\"].values[0],\n",
    "    }))\n",
    "    .assign(\n",
    "        overlap_human_retrieved=lambda df: df.apply(lambda row: jaccard(row[\"cited_ids_human\"], row[\"retrieved_ids\"]), axis=1),\n",
    "        overlap_llm_retrieved=lambda df: df.apply(lambda row: jaccard(row[\"cited_ids_llm\"], row[\"retrieved_ids\"]), axis=1),\n",
    "        overlap_human_llm=lambda df: df.apply(lambda row: jaccard(row[\"cited_ids_human\"], row[\"cited_ids_llm\"]), axis=1),\n",
    "        correlation_human_retrieved=lambda df: df.apply(lambda row: spearmanr(row[\"cited_ids_human\"], [x for x in row[\"retrieved_ids\"] if x in row[\"cited_ids_human\"]])[0], axis=1),\n",
    "        correlation_llm_retrieved=lambda df: df.apply(lambda row: spearmanr(row[\"cited_ids_llm\"], [x for x in row[\"retrieved_ids\"] if x in row[\"cited_ids_llm\"]])[0], axis=1),\n",
    "        correlation_human_llm=lambda df: df.apply(lambda row: spearmanr([x for x in row[\"cited_ids_human\"] if x in row[\"cited_ids_llm\"]], [x for x in row[\"cited_ids_llm\"] if x in row[\"cited_ids_human\"]])[0], axis=1),\n",
    "        size_human_human=lambda df: df[\"cited_ids_human\"].apply(len),\n",
    "        size_llm_llm=lambda df: df[\"cited_ids_llm\"].apply(len),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(columns=[\"cited_ids_human\", \"cited_ids_llm\", \"retrieved_ids\", \"topic\"])\n",
    "    .groupby(\"style\")\n",
    "    .describe()\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        measure=lambda df: df[\"level_0\"].apply(lambda s: s.split(\"_\")[0]),\n",
    "        first=lambda df: df[\"level_0\"].apply(lambda s: s.split(\"_\")[1]),\n",
    "        second=lambda df: df[\"level_0\"].apply(lambda s: s.split(\"_\")[2]),\n",
    "    )\n",
    "    .drop(columns=\"level_0\")\n",
    "    .melt(id_vars=[\"measure\", \"first\", \"second\", \"level_1\"])\n",
    "    .query(\"level_1 in ['mean', 'std', 'count']\")\n",
    "    .pivot(index=[\"style\", \"measure\", \"first\", \"second\"], columns=[\"level_1\"], values=\"value\")\n",
    "    #.assign(pm=lambda df: 1.96*df[\"std\"]/df[\"count\"].apply(np.sqrt))\n",
    "    .loc[:, [\"mean\", \"std\"]]\n",
    "    .reset_index()\n",
    "    .melt(id_vars=[\"style\", \"measure\", \"first\", \"second\"])\n",
    "    .pivot(index=[\"measure\", \"first\", \"second\"], columns=[\"style\", \"level_1\"], values=\"value\")\n",
    "    .loc[:, [(\"bullet\", \"mean\"), (\"bullet\", \"std\"), (\"essay\", \"mean\"), (\"essay\", \"std\"), (\"news\", \"mean\"), (\"news\", \"std\")]]\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    ")"
   ],
   "id": "4c60f5e5d573b451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sacrebleu import BLEU\n",
    "\n",
    "metric = BLEU(lowercase=True, max_ngram_order=8, effective_order=True)\n",
    "\n",
    "bleu_data = (\n",
    "    pd.read_json(\"../data/artifacts/responses.jsonl.gz\", lines=True)\n",
    "    .loc[:, [\"response\", \"style\", \"kind\", \"topic\", \"statements\"]]\n",
    "    .explode(\"statements\")\n",
    "    .set_index([\"response\", \"style\", \"kind\", \"topic\"])\n",
    "    .assign(\n",
    "        original_text=lambda df: df[\"statements\"].apply(lambda c: c[\"text\"]), \n",
    "        citations=lambda df: df[\"statements\"].apply(lambda c: c[\"citations\"]) \n",
    "    )\n",
    "    .explode(\"citations\")\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "        (\n",
    "            pd.read_json(\"../data/raw/study1_retrieval.jsonl.gz\", lines=True)\n",
    "            .loc[:, [\"references_ids\", \"references_texts\"]]\n",
    "            .explode([\"references_ids\", \"references_texts\"])\n",
    "            .drop_duplicates()\n",
    "            .rename(columns={\"references_ids\": \"citations\"})\n",
    "        ),\n",
    "        on=\"citations\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .drop(columns=[\"statements\", \"citations\"])\n",
    "    .set_index([\"topic\", \"style\", \"kind\", \"response\"])\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda row: metric.sentence_score(row[\"original_text\"], row[\"references_texts\"].split(\"\\n\")), axis=1)\n",
    "    .apply(lambda row: pd.Series({\"score\": row.score, \"counts\": row.counts}))\n",
    ")"
   ],
   "id": "c38ffe1a2ff8062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(3.64, 1.7), ncols=2, width_ratios=(1, 4), sharey=True, sharex=False)\n",
    "\n",
    "sns.ecdfplot(\n",
    "    bleu_data.reset_index().query(\"kind == 'human'\"),\n",
    "    x=\"score\",\n",
    "    hue=\"style\",\n",
    "    ax=ax[1],\n",
    ")\n",
    "\n",
    "sns.ecdfplot(\n",
    "    bleu_data.reset_index().query(\"kind == 'llm'\"),\n",
    "    x=\"score\",\n",
    "    hue=\"style\",\n",
    "    ax=ax[0],\n",
    "    legend=False,\n",
    ")\n",
    "ax[0].set_xlim(0, 25)\n",
    "ax[1].set_xlim(0, 100)\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"citations-bleu-score.pdf\")"
   ],
   "id": "e865d86f032d76e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.lineplot(\n",
    "    data = (\n",
    "        bleu_data\n",
    "        .reset_index()\n",
    "        .loc[:, [\"topic\", \"style\", \"kind\", \"counts\"]]\n",
    "        .set_index([\"topic\", \"style\", \"kind\"])\n",
    "        .apply(lambda row: pd.Series(dict(zip(range(1, len(row.values[0])+1), row.values[0]))), axis=1)\n",
    "        .groupby([\"style\", \"kind\"])\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .melt(id_vars=[\"style\", \"kind\"])\n",
    "    ),\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    hue=\"kind\",\n",
    "    style=\"style\"\n",
    ")"
   ],
   "id": "b095f6449a5796cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "g = sns.FacetGrid(\n",
    "    data=(\n",
    "        pd.read_json(\"../data/artifacts/responses.jsonl.gz\", lines=True)\n",
    "        .loc[:, [\"response\", \"topic\", \"style\", \"kind\", \"statements\"]]\n",
    "        .assign(\n",
    "            statement_lengths=lambda df: (\n",
    "                df[\"statements\"]\n",
    "                .apply(lambda cell: [len(s[\"text\"]) for s in cell])\n",
    "            ),\n",
    "            statement_references=lambda df: (\n",
    "                df[\"statements\"]\n",
    "                .apply(lambda cell: [len(s[\"citations\"]) for s in cell])\n",
    "            )\n",
    "        )\n",
    "        .assign(\n",
    "            statement_lengths_normalized=lambda df: (\n",
    "                df[\"statement_lengths\"]\n",
    "                .apply(lambda cell: np.cumsum(cell) / np.sum(cell))\n",
    "            )\n",
    "        )\n",
    "        .drop(columns=[\"statements\", \"response\", \"topic\", \"statement_lengths\"])\n",
    "        .explode([\"statement_references\", \"statement_lengths_normalized\"])\n",
    "        .query(\"(statement_references != 0)\")\n",
    "        .rename(columns={\"statement_lengths_normalized\": \"Relative Position\"})\n",
    "    ),\n",
    "    col=\"style\",\n",
    "    legend_out=False,\n",
    "    aspect=0.5,\n",
    "    height=3.64\n",
    ")\n",
    "g.map_dataframe(sns.kdeplot, x=\"Relative Position\", hue=\"kind\")\n",
    "\n",
    "for ax in g.axes:\n",
    "    ax[0].set_xlim(0,1)\n",
    "\n",
    "g.add_legend()\n",
    "g.savefig(\"citations-position.pdf\")\n",
    "plt.show()"
   ],
   "id": "3a60468fafde3ea2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
