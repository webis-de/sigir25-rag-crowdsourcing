{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from sacrebleu import sentence_bleu\n",
    "import bert_score\n",
    "from rouge_score import rouge_scorer\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "DIMENSIONS = [\"correctness_topical\", \"coherence_logical\", \"coherence_stylistic\", \"coverage_broad\", \"coverage_deep\", \"consistency_internal\", \"quality_overall\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rouge = rouge_scorer.RougeScorer(['rouge1', \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "def content_overlap_correlation(group):\n",
    "    corr = {}\n",
    "    for dim in DIMENSIONS:\n",
    "        data = group.sort_values(dim, ascending=False)\n",
    "        reference = data[\"cleaned_text\"].iloc[0]\n",
    "        hypotheses = data[\"cleaned_text\"].iloc[1:]\n",
    "        ranking = data[dim].iloc[1:].values\n",
    "        scores_bleu = [sentence_bleu(reference, [hyp]).score for hyp in hypotheses]\n",
    "        scores_rogue = [rouge.score(reference, hyp)[\"rougeL\"].fmeasure for hyp in hypotheses]\n",
    "        _, _, scores_bertscore = bert_score.score(list((reference,))*5, [[x] for x in hypotheses], lang=\"eng\")\n",
    "        corr[(dim, \"full\", \"bleu\")] = spearmanr(ranking, scores_bleu)[0]\n",
    "        corr[(dim, \"full\", \"rougeL\")] = spearmanr(ranking, scores_rogue)[0]\n",
    "        corr[(dim, \"full\", \"bertscore\")] = spearmanr(ranking, scores_bertscore)[0]\n",
    "        corr[(dim, \"bw\", \"bleu\")] = spearmanr([ranking[0], ranking[-1]], [scores_bleu[0], scores_bleu[-1]])[0]\n",
    "        corr[(dim, \"bw\", \"rougeL\")] = spearmanr([ranking[0], ranking[-1]], [scores_rogue[0], scores_rogue[-1]])[0]\n",
    "        corr[(dim, \"bw\", \"bertscore\")] = spearmanr([ranking[0], ranking[-1]], [scores_bertscore[0], scores_bertscore[-1]])[0]\n",
    "    \n",
    "    return pd.Series(corr)"
   ],
   "id": "56603f11cff0cc91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_corr = (\n",
    "    pd.read_json(\"../data/artifacts/responses.jsonl.gz\", lines=True)\n",
    "    .merge(\n",
    "        pd.read_json(\"../data/artifacts/grades.jsonl.gz\", lines=True),\n",
    "        on=\"response\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .dropna(subset=\"quality_overall\")\n",
    "    .groupby(\"topic\")\n",
    "    .progress_apply(content_overlap_correlation)\n",
    ")"
   ],
   "id": "160325a62067b988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_corr.mean(axis=0).reset_index().pivot(index=[\"level_1\", \"level_2\"], columns=[\"level_0\"], values=0).round(3).transpose()",
   "id": "f254a2161b92f62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b11ed6deefc0b3e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
