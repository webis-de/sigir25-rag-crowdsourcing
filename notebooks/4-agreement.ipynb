{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "\n",
    "def has_majority_vote(data: List[str]):\n",
    "    return pd.Series(data).value_counts().sort_values(ascending=False).iloc[0] > 2\n",
    "\n",
    "def get_agreement(\n",
    "    df, \n",
    "    item_column_name: str = \"item\", \n",
    "    worker_column_name: str = \"worker\", \n",
    "    value_column_name: str = \"value\",\n",
    "    value_domain: List[str] = None\n",
    "):\n",
    "    if value_domain is None:\n",
    "        value_domain = [\"A\", \"N\", \"B\"]\n",
    "        \n",
    "    rel_data = df.pivot(index=worker_column_name, columns=item_column_name, values=value_column_name).values.astype(\"U\")\n",
    "    alpha = krippendorff.alpha(reliability_data=rel_data, level_of_measurement=\"ordinal\", value_domain=value_domain)\n",
    "    return round(float(alpha), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cols =  [\"correctness_topical\", \"coherence_logical\", \"coherence_stylistic\", \"coverage_broad\", \"coverage_deep\", \"consistency_internal\", \"quality_overall\"]",
   "id": "37e2bae1204b5f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_expert = (\n",
    "    pd.read_json(\"../data/raw/expert-response.jsonl.gz\").query(\"prolific_pid in ['annot1', 'annot2', 'annot4']\")\n",
    "    .rename(columns={\"validity\": \"correctness_topical\"})\n",
    ")\n",
    "\n",
    "agreement_data = []\n",
    "for col in cols:\n",
    "    alpha_expert_hard = get_agreement(\n",
    "        df_expert\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            worker=lambda df: df[\"prolific_pid\"], \n",
    "            value=lambda df: df[col]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    alpha_crowd_hard = get_agreement(\n",
    "        df_expert.loc[:, [\"query_id\", \"response_a\", \"response_b\"]]\n",
    "        .merge(\n",
    "            pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "            .loc[:, [\"query_id\", \"response_a\", \"response_b\", f\"{col}_vote\", \"worker\"]]\n",
    "        )\n",
    "        .explode([f\"{col}_vote\", \"worker\"])\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            value=lambda df: df[f\"{col}_vote\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    alpha_crowd_corrected = get_agreement(\n",
    "        pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "        .assign(ab=lambda df: df.loc[:, [\"response_a\", \"response_b\"]].apply(sorted, axis=1))\n",
    "        .drop_duplicates(subset=\"ab\").drop(columns=\"ab\")\n",
    "        .loc[:, [\"query_id\", \"response_a\", \"response_b\", f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\"]]\n",
    "        .explode([f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\", ])\n",
    "        .query(f\"{col}_spam_probability <= 0.7\")\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            value=lambda df: df[f\"{col}_vote\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    alpha_crowd_uncorrected = get_agreement(\n",
    "        pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "        .loc[:, [\"query_id\", \"response_a\", \"response_b\", f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\"]]\n",
    "        .explode([f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\", ])\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            value=lambda df: df[f\"{col}_vote\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    alpha_crowd_easy_uncorrected = get_agreement(\n",
    "        (\n",
    "            pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "            .assign(\n",
    "                decidable = lambda df: (\n",
    "                    # Filter question cols\n",
    "                    df.loc[:, [col for col in df.columns if \"vote\" in col]]\n",
    "                    # Count which questions have a majority vote\n",
    "                    .apply(lambda col: col.apply(has_majority_vote), axis=1)\n",
    "                    # Check if the majority of questions have a majority vote\n",
    "                    .apply(lambda row: row.sum() > 4, axis=1)\n",
    "                )\n",
    "            )\n",
    "            .query(\"decidable == True\")\n",
    "        )\n",
    "        .loc[:, [\"query_id\", \"response_a\", \"response_b\", f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\"]]\n",
    "        .explode([f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\", ])\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            value=lambda df: df[f\"{col}_vote\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    alpha_crowd_easy_corrected = get_agreement(\n",
    "        (\n",
    "            pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "            .assign(\n",
    "                decidable = lambda df: (\n",
    "                    # Filter question cols\n",
    "                    df.loc[:, [col for col in df.columns if \"vote\" in col]]\n",
    "                    # Count which questions have a majority vote\n",
    "                    .apply(lambda col: col.apply(has_majority_vote), axis=1)\n",
    "                    # Check if the majority of questions have a majority vote\n",
    "                    .apply(lambda row: row.sum() > 4, axis=1)\n",
    "                )\n",
    "            )\n",
    "            .query(\"decidable == True\")\n",
    "        )\n",
    "        .loc[:, [\"query_id\", \"response_a\", \"response_b\", f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\"]]\n",
    "        .explode([f\"{col}_vote\", f\"{col}_spam_probability\", \"worker\", ])\n",
    "        .query(f\"{col}_spam_probability <= 0.7\")\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            item=lambda df: df[\"response_a\"] + df[\"response_b\"], \n",
    "            value=lambda df: df[f\"{col}_vote\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    agreement_data.append({\n",
    "        \"dimension\": col, \n",
    "        \"expert_hard\": alpha_expert_hard, \n",
    "        \"crowd_hard\": alpha_crowd_hard,\n",
    "        \"crowd_complete_uncorrected\": alpha_crowd_uncorrected,\n",
    "        \"crowd_complete_corrected\": alpha_crowd_corrected,\n",
    "        \"crowd_easy_uncorrected\": alpha_crowd_easy_uncorrected,\n",
    "        \"crowd_easy_corrected\": alpha_crowd_easy_corrected,\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(agreement_data).round(2).to_latex())"
   ],
   "id": "d24a53323f9a88a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(agreement_data).round(2)",
   "id": "76efd1300206a5ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(agreement_data).set_index(\"dimension\").mean(axis=0).round(2)",
   "id": "e7821a56316c5b48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True))",
   "id": "9596b10c2e3a6d55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "len(\n",
    "    pd.read_json(\"../data/artifacts/ratings.jsonl.gz\", lines=True)\n",
    "    .assign(\n",
    "        decidable = lambda df: (\n",
    "            # Filter question cols\n",
    "            df.loc[:, [col for col in df.columns if \"vote\" in col]]\n",
    "            # Count which questions have a majority vote\n",
    "            .apply(lambda col: col.apply(has_majority_vote), axis=1)\n",
    "            # Check if the majority of questions have a majority vote\n",
    "            .apply(lambda row: row.sum() > 4, axis=1)\n",
    "        )\n",
    "    )\n",
    "    .query(\"decidable == False\")\n",
    ")"
   ],
   "id": "4a17c561ed281ec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "len(\n",
    "    pd.read_json(\"../data/raw/expert-response.jsonl.gz\")\n",
    "    .query(\"prolific_pid in ['annot1', 'annot2', 'annot4']\")\n",
    "    .groupby([\"response_a\", \"response_b\"])\n",
    "    .count()\n",
    ")"
   ],
   "id": "1ed2656cb6435d42",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
